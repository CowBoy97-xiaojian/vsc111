一、在线云迁移
    1、离线平台的使用(组件使用、调度执行、接口文件推送)
    2、实时平台的使用(组件使用、任务部署、问题排查)
        验证cdp-kafka数据并解析。

二、seatunnel维护
    1、seatunnel维护手册。
    2、seatunnel-udf方法上传git。
    3、月初保障,seatunnel
三、值班重保

四、任务接收
1、小程序性能代码版本迭代.小程序数据核对，生成测试报告，并发送邮件。
2、权益51007接口开发。
3、分省接口对接,山东和浙江。
4、51007离线接口口径升级:将安卓和IOS的area_id和type的条件去掉【2024-03-14】
5、77006历史账期数据回填。
6、cache-core程序迁移。【韩钰两个程序没有确定下来2024-03-29】
7、51007接口11到14号数据重推【2024-03-14】
8、app工单表数据匹配口径【完成】
9、营服服务器资源申请【机器到位】
10、wt_ed、no变name口径变更【2024-03-14】
11、质量纳管【2024-03-29】
12、51007增加渠道号【2024-03-29】
13、分省CM001数据统一。
14、seatunnel数据解密发送营服做数据适配.
15、数据日报
16、wt_es 中 原生调整
17、小程序性能问题排查
    @何勇 @棉花 @潘明保 @坤 总结小程序性能数据部分耗时字段丢失问题，通过对51007报文数据、消费插码侧的离线库数据以及一二级平台数据库和过滤库分析，发现客户端侧上报部分耗时数据的pfm密文中path字段传输为空，导致入一二级平台时将此类数据置于过滤库中，进而导致页面查询部分字段为空（以业务耗时字段为主），我们平台计划在4月9日调整过滤逻辑，同时从过滤库中恢复近1个月的耗时数据@张福生 ，后续持续观察耗时数据情况@👑；
同时，麻烦客户端同事@小明_CIUM @クウハク 提供一份最新的小程序4类耗时数据的密文字段传输规则及样例（安卓和IOS）；
感谢客户端和插码同事的配合@牛仔很忙的； @小明_CIUM @クウハク @M ；
18、确定XY的数据格式。
19、流程处理
    1、开发:模型开发、程序开发、数据交换（单元开发）
    2、上线:模型开发、程序开发、数据交换（单元开发）
    3、测试
    4、
20、计提材料
    需求报告
    上线报告
    测试报告
21、代办事项：审计材料、博新数据调整、离线平台熟悉、工作量编写
22、山东实时数据缺失问题排查
23、
    草稿各位老师好：
        由于近期迁移工程需要进行资源回收，我们进行资源复用，将老sdk程序进行优化，主要涉及51006、51007、51010接口，从20240416账期开始进行升级，劳烦各位老师验证一下数据情况，如有问题请及时联系我们，望各位老师知悉。

    正式发送各位老师好：
        插码系统内部进行链路优化，主要涉及51006、51007、51010接口，从20240416账期开始进行升级，劳烦各位老师验证一下数据情况，如有问题请及时联系我们，望各位老师知悉。

        
24、权益超市维表
0001_00100_20240415_001.txt.gz
0001_00101_20240415_001.txt.gz
0001_00200_20240415_001.txt.gz
0001_00300_20240415_001.txt.gz
0001_00400_20240415_001.txt.gz
dwd_ts_mk_block_cul_20240415.csv
dwd_ts_mk_block_cul_by_channel_20240415.csv
dwd_ts_mk_block_cul_by_channel_vi_20240415.csv
dwd_ts_mk_block_cul_by_vip_20240415.csv
dwd_ts_mk_member_cul_20240415.csv
dwd_ts_mk_member_cul_by_vip_20240415.csv
dwd_ts_mk_page_cul_20240415.csv
dwd_ts_mk_page_cul_by_channel_20240415.csv
dwd_ts_mk_page_cul_by_channel_vi_20240415.csv
dwd_ts_mk_page_cul_by_vip_20240415.csv
dwd_ts_mk_posi_cul_20240415.csv
dwd_ts_mk_posi_cul_by_channel_20240415.csv
dwd_ts_mk_posi_cul_by_channel_vi_20240415.csv
dwd_ts_mk_posi_cul_by_vip_20240415.csv
dwd_ts_mk_total_cul_20240415.csv
dwd_ts_mk_total_cul_by_channel_20240415.csv
dwd_ts_mk_total_cul_by_channel_vi_20240415.csv
dwd_ts_mk_total_cul_by_vip_20240415.csv
fsuvzh_20240415.csv
fsuvzh_detail_20240415.csv
jtqs_20240415.csv
yhxxb.csv
ymtlscmxb.csv
ymxxb.csv
ztpjtlscb.csv
zttlscmxb.csv
zunxiangliyu_20240415.csv
全渠道汇总表_20240415.CP.csv
国庆节活动报表channelid_pageid_20240415.csv
国庆节活动报表_汇总_20240415.csv
基础码数据表_20240415.CP.csv
25、wt对数逻辑
工作量 
    自己填写自己的，以实际为主，哪个周次干的工作就填写到对应的周次里面去。
    有上线报告的工作量一定要和工作量相对应。
    之后会用研发云进行工作量填报，每个人都要用研发云进行工作量时间记录。
    周五之前把工作量填写完成，每个月第二周把自己的计提工作量填完。
26、5月9日迁移磐道

    对数思路
    一、代码
    1、51007改动不大
    2、51006改动比较大

    二、对数思路    
     1、限制时间戳、渠道号、手机号  取出唯一一条数据，所有字段进行对比。
     2、null字段  所有数据group by后的结果取前100个，对比数据格式和数据内容
     3、对枚举字段继续group，对比每一个枚举值的数据量差异值   
     4、数据量总量-小时、天、渠道号、接口层数据
     5、特殊数据对比 ip-prov、ua
     6、出现问题---ua、attrubutes、xy
26、domain逻辑下线


27、在线营服问题解决
展锋老师，我们这面有两个问题
1、查询插入数据的时候报空指针异常，执行多次后就会执行成功， 而且程序本身有三次重跑。
2、查询一天的数据会报内存溢出的问题。
能帮忙找一下相应的老师约个会议解决一下吗。

28、迁移进度
1、hive全量数据写入测试。
2、完成13个离线调度迁移，预计下线10个离线调度，还剩6离线调度正在进行中,全部调度预计在4月25日完成代码开发。
3、预计4月28日完成dwd层数据量及数据内容对比。
4、网状网、磐道推送速率测试。
5、19个离线接口数据对比。
29、51007数据对数
30、网状网和磐道到营服的网络速度问题

31、重启seatunnel的脚本程序
Job ID              Job Name       Job Status  Submit Time              Finished Time            
------------------  -------------  ----------  -----------------------  -----------------------  
836170467365617672  hive_newudf    RUNNING     2024-04-28 01:10:13.67   
836170981650202632  kafka_yfkafka  RUNNING     2024-04-26 09:31:03.85   

31、营服数据积压情况4-28、4-29

32、ip-udf函数适配



在xy字段里面剔除经纬度信息
1、开发UDF函数
2、通过HDFS账号上传到hdfs，/hive-udf/下
3、通过
create function IpRegion as 'com.udf.IpRegion' using jar 'hdfs://udbachdp1/hive-udf/ip-1.0.jar';
新建hive方法
4、测试生成的方法z
5、替换原先的方法并观察新生成的数据

33、权益18张报表下线
各位老师好：
    由于插码系统正在迁移至在线云平台，需要对现有接口进行梳理。将于5月7日停止下发以下接口文件，如还有使用请及时联系我们进行数据迁移，未收到反馈将于5月14号进行接口下线。望各位老师知晓。
0001_00100_20240415_001.txt.gz
0001_00101_20240415_001.txt.gz
0001_00200_20240415_001.txt.gz
0001_00300_20240415_001.txt.gz
0001_00400_20240415_001.txt.gz
dwd_ts_mk_block_cul_20240415.csv
dwd_ts_mk_block_cul_by_channel_20240415.csv
dwd_ts_mk_block_cul_by_channel_vi_20240415.csv
dwd_ts_mk_block_cul_by_vip_20240415.csv
dwd_ts_mk_member_cul_20240415.csv
dwd_ts_mk_member_cul_by_vip_20240415.csv
dwd_ts_mk_page_cul_20240415.csv
dwd_ts_mk_page_cul_by_channel_20240415.csv
dwd_ts_mk_page_cul_by_channel_vi_20240415.csv
dwd_ts_mk_page_cul_by_vip_20240415.csv
dwd_ts_mk_posi_cul_20240415.csv
dwd_ts_mk_posi_cul_by_channel_20240415.csv
dwd_ts_mk_posi_cul_by_channel_vi_20240415.csv
dwd_ts_mk_posi_cul_by_vip_20240415.csv
dwd_ts_mk_total_cul_20240415.csv
dwd_ts_mk_total_cul_by_channel_20240415.csv
dwd_ts_mk_total_cul_by_channel_vi_20240415.csv
dwd_ts_mk_total_cul_by_vip_20240415.csv
fsuvzh_20240415.csv
fsuvzh_detail_20240415.csv
jtqs_20240415.csv
yhxxb.csv
ymtlscmxb.csv
ymxxb.csv
ztpjtlscb.csv
zttlscmxb.csv
zunxiangliyu_20240415.csv
全渠道汇总表_20240415.CP.csv
国庆节活动报表channelid_pageid_20240415.csv
国庆节活动报表_汇总_20240415.csv
基础码数据表_20240415.CP.csv

34、CM博新数据下线

各位老师好：
    将于20240507账期对CM001接口中的原生数据进行调整，将老SDK的IOS,ANDROID渠道的双采数据停止下发,以"a1f48d9ff4f42571"-ANDROID,"b508a809cbbddd0b"-IOS为采集渠道号。
    原下发的渠道有:"b95440ef47ec01fc","a1f48d9ff4f42571","b508a809cbbddd0b","H5","IOS","ANDROID"
    调整后为:"b95440ef47ec01fc","a1f48d9ff4f42571","b508a809cbbddd0b","H5"

33、数据迁移到磐道 5-9



















2024年4月23日
1、微批入hive确认可行性（张建超）；
2、google protobuf格式UDF函数，与在线云沟通代码修改（张建超）；
3、F5公网IP申请，提交网络策略单，开通F5到nginx、nginx到collector策略（尚文强找汤泽宇沟通）；
4、采集collector部署与压力测试，已经完成，需要与在线沟通反馈排查问题（尚文强）；
5、直接写入hive性能不达标，需要和在线云沟通增加分区（单沛丰）；
2024年4月23日
1、完成了所有51系列调度迁移（张建超）；
2、完成了google protobuf格式UDF函数，与在线云沟通代码修改（张建超，重大进展）；
3、写入hive 用flink sql，性能测试通过，脏数据会报错，已经解决（单沛丰，重大进展）；
4、IP和UA函数无进展（单沛丰）；
5、于昨日已经提交IP V6负载均衡网络策略单，待贾老师审批，已催促（尚文强）；
6、采集collector压力测试一轮完成，需要优化进行二轮测试（尚文强）；

明日计划：
1、如果IP V6审批下来，接着搞F5到NG，NG到collector的策略单申请（尚文强）；
2、采集collector进行二轮测试（尚文强）；
3、进行51系列对数（张建超）；
4、google protobuf格式UDF函数继续跟进沟通、反馈（张建超）；
5、IP和UA函数跟踪反馈（单沛丰）；

2024年4月24日
1、进行51系列中间表对数-进度30%（张建超）；
2、除分省系列，其他迁移完的接口已经上线，开始进行调度测试（张建超）；
3、协助营服平台将protobuf格式数据解析为EventDto对象（张建超）；
4、完成collector进行二轮测试（尚文强）；
5、UA、IP代码优化、测试（单沛丰）；

明日计划：
1、继续进行51系列中间表对数（张建超）；
2、营服CM系列开发（张建超）；
3、提升营服接口机到网状网的传输速率（尚文强）；
4、如果IP V6审批下来，接着搞F5到NG，NG到collector的策略单申请（尚文强）；
5、IP和UA函数跟踪反馈（单沛丰）；

2024年4月28日
1、营服实时资源申请，构建ITcdpkafka到营服kafka的性能测试程序。
2、IP和UA函数跟踪反馈（单沛丰）。
3、进行51006、51010接口层对数-进度30%（张建超）。
4、进行51007接口层对数-进度30%（张建超）。
4、营服CM系列开发20%（张建超）；
5、提升营服接口机到网状网的传输速率，已经联系的对应负责人，正在进行联调（王峰）。
6、shotpot采集服务部署，正在测试（尚文强）。
7、进行51系列中间表对数-进度30%（张建超）；

明日计划：
1、完成进行51系列接口层对数（张建超）；
2、继续营服CM系列开发和对数（张建超）；
3、提升营服接口机到网状网的传输速率（王峰）；
4、继续shotpot采集部署（尚文强）；；
5、IP和UA函数跟踪反馈（单沛丰）；

2024年4月29日
@潘达 @陈刚 两位领导，关于在线云接口机上传文件网速慢今天的排查情况汇报如下：
1、前提背景：
	①IT云上传到网状网走的是内网，传输的网速为135M；
	②在线云到网状网或者磐道只能走【承载网】，在走承载网的时候出现网速只有2M的现象；
	③当前接口机使用的承载网网络流转：在线云接口机->在线云负载->磐道或者网状网负载->磐道或者网状网后端服务。
2、问题定位：
	①磐道或者网状网的负载使用的是7层转发，今天经过跳过负载测试，网速可以达到25M，所以判断是负载7层转发影响了网速；
	②因为负载影响，需要我们需要开通在线云接口机直通磐道后端服务的网络策略，跳过负载。

3、处理进度:
	①为了解决负载7层转发影响，现已完成协调网状网侧调整负载事宜【涉及胡意军、高国青】，于今晚8点进行7转4层的调整，预测调整后网速应该可以达到20M；
	②为跳过负载，现已完成在线云接口机直通磐道服务机器的网络策略申请。但是由于假日封网，预计在5月7日晚开通该网络策略。
4、后续问题：
	不管是负载7转4，还是跳过负载的网络，网速都有可能达不到现在内网的135M速度。经过沟通确认，磐道服务机器的带宽为1G，理论网速为125M左右。后期跳过负载的网速若还是25M左右，就要排查磐道服务机器的入口网络以及在线云接口机这边的出口网络，从而解决可能存在的问题。
@陈刚 @潘达 ，接上述内容，网状网负载已经完成7转4，网速提升了6倍，达到12M。这个网速还是满足不了接口传输速度要求，只能等后续等跳过负载的网络开通后，再看下网速。


2024年5月06日

1、Nginx部署、证书加载【汤泽宇】
2、Kafka部署【禹果】
3、系统情况巡检
4、69  sftp情况
5、cache-core-6 7物理机下线，块存储。

五、历史遗留问题
    1、质量纳管程序编译。
    2、质量纳管文件名更正。
    3、小程序性能数据校验。
    4、离线代码上传git。
    我不访问大表  我想在我们机器上传点测试数据到营服，现在只有这个通路能走，所有我们需要这个


六、在线云迁移
1、定期发邮件
2、在线云迁移计划

一、迁移在线云-数据接入:
    1、从IT的cdp-kafka接入营服并注册，网络策略打通，正常消费到cdp-kafka的数据。【完成】
    2、需要一个100个分区的topic：cdp-event-protobuf。【李家弦】
    3、将cdp-kafka中cdp-event-collect数据解密发送到cdp-event-protobuf。【单沛丰】
        使用seatunnel进行数据解密。
    4、流处理平台flink程序编写：从营服到hive，并进行性能测试。【单沛丰】
二、迁移在线云-数据传输：
    1、确定好数据传输链路【营服、网状网】。【岑俊杰】
    2、开通网路【磐道、网状网、hdfs-DACP和接口机开通网络】。【尚文强】
    3、确保接口机可以访问到hadoop、hashdata、openGuess、seatunnel。【韩钰】
    4、扩充到磐道、网状网的网络带宽。【尚文强】
三、离线数据迁移
    1、梳理离线所有调度，下线已经不使用的离线调度。
    2、将离线程序迁移到在线营服。
    3、进行数据验证。
四、离线数据验证

五、下线hadoop和seatunnel。
六、实时程序迁移。
七、实时程序验证。

强调测试结果来决定资源调整


3、申请营服账号
vpn： 尚文强，张建超，韩钰，岑俊杰，陈刚（申请）        王峰、林仁辉（延期）

确定一下以下人员是否有账号
在线4a，营服平台：马博、文凯、敬晶、陈刚





    
建超，以后按周定期群发邮件，本周主要进展内容或完成的里程碑及待协调推进工作写在邮件正文里，发送范围为：
主送：王国飞，如有系统平台中心其他同事也可以加上，潘湘飞、马建、陈刚
抄送：系统崔总、郭总、我、丽华
相关邮箱湘飞提供。
此致
礼！
邓猛
中国移动通信集团在线营销服务中心 渠道支撑中心
移动电话： 15888883535
电子邮件：dengmeng@cmos.chinamobile.com

系统平台中心
王国飞：wangguofei@cmos.chinamobile.com
齐展峰：qizhanfeng@cmos.chinamobile.com
苏克云：sukeyun@cmos.chinamobile.com
汤泽宇：tangzeyu@cmos.chinamobile.com
张光锐：zhangguangrui@cmos.chinamobile.com

抄送：
崔洪涛总：cuihongtao@cmos.chinamobile.com
郭建民总：guojianminzx@cmos.chinamobile.com
邓猛总：dengmeng@cmos.chinamobile.com
贾丽华：jialihua@cmos.chinamobile.com

系统崔总、郭总、我、丽华

#2024-03-15
本周进展：
1、插码侧协同系统平台中心完成制定营服流处理平台上实时数据多流输出的解决方案。
2、插码侧协同系统平台中心完成用于生成接口文件的测试主机申请及4a账号绑定。
3、80台物理机完成机房实施,服务组件安装预计3月24日之前完成@王国飞。

待推进事项：
1、急需开通营服流处理平台与IT云插码系统cdp kafka集群通信的网络策略@王峰@苏克云，务必3月19日之前完成。
2、解析数据采集源端kafka中的加密数据，需要在线营服平台进行定制化开发，请@苏克云老师评估技术方案，并反馈完成时间。
3、请@谢江涛老师安排同事协助插码侧完成在线营服平台生成接口文件并对外传输的整体链路测试。
4、请@李云帆老师评估裸金属机器虚拟化部署方案，并反馈完成时间。【裸金属交付】

迁移进展详情见附件。

#2024-03-22
本周进展：
1、解析数据采集源端kafka中的加密数据方案已确定，方案如下：
    方案一：系统平台中心定制化开发kafka反序列化组件。
    方案二：使用seatunnel进行数据解析处理。
    两套方案并行推进
2、营服流处理平台与IT云插码系统cdp kafka集群通信的网络策略已经开通。
3、在线营服用于搭建hadoop容器的20台主机已经申请并进行容器化。
4、完成在线营服平台生成接口文件并对外传输的整体链路测试。

待推进事项：

#2024-03-29
本周进展：
运维
1、完成裸金属申请。
2、cdp-kafka和cache-core-new 集群和营服的网络已经开通，并接入数据到营服平台。
3、接口机完成程序账号绑定和dacp调度平台绑定。

数据开发
1、在IT云使用seatunnel组件将kafka中二进制数据解析为标准json格式，写入Kafka。
2、营服流处理平台消费解析后的kafka数据并写入营服Hive。
3、hive-udf测试已经完成。
4、hashdata数据写入测试已经完成。

插码侧实施进度方面：（1）申请的8台裸金属主机已全部完成分配及4A账号绑定(2)在IT云使用seatunnel组件将kafka中二进制数据解析为标准json格式并写入Kafka。(3)营服流处理平台消费解析后的kafka数据并写入营服Hive及Hashdata。(4)完成插码专用文件处理接口机sftp账号新建并在Dacp调度平台的注册与绑定，以便后续数据接口文件推送网状网。

下周计划：

1、ods到dwd离线调度开发。
2、在营服流处理平台完成一个实时接口任务整体流程部署。


2、待开展事项
    1、ip、userAgent方法解析
    2、sink多流topic
    3、protobuf格式数据解析---flink解析完成之后发送到cache-core-new上面。将数据发送到他们的kafka
    4、源头数据解析
    5、评估一下营服的flink资源使用情况
    6、评估cdp-kakfa 存储容量评估是否满足两份数据的存储，是不是需要开通cach-core-new的网络策略
        cdp-kafka磁盘资源评估。
        确定与营服网络是否可以开通。

    7、潘湘飞账号操作机器   需要正式恢复邮件解释违规操作
       俊杰账号需要写一个授权书
       编写一个安全责任书
    8、flink资源申请【已经到位】
    9、主机资源绑定-需要厂商的入场资料
    10、
    
系统漏洞
硬件维护
应用漏洞


月初重保
    1、系统情况巡检。
    2、邮件通知业务方。
    3、巡检工作。

问题1
1、营服消费cache-core-new集群，消费速率每分钟只有400K-提高并行度
2、flinksql数据监控---数据的写入速度没有办法监控
    hive和hdfs的入库性能无法监控
    hdfs load加载
3、hashdata写入数据量太大-写入分区错乱，用正式扩容的数据库进行测试
    hive数据同步到hashdata
    hashdata无法建分区表，需要手动创建未来的分区。
    实时写入数据预估高峰天高峰16亿，接收51007数据导致hashdata到达瓶颈
4、实时数据入hdfs数据入库情况验证
5、ua和ip适配问题

问题2
1、flink写hive性能测试。
2、hashdata正式数据源接入，hashdata读取hive里面的数据。
3、ua和ip找个专项会议解决。
4、营服seatunnel搭建。

问题3
在线营服批处理系统培训
1、hive数据库
2、是否为公共表
3、敏感字段建表的时候会告诉你
4、表变更，只能把表删除了重新创建吗，不涉及表结构的结构变更需要重新上线吗。

ods是parquet格式，
dwd是orc，不压缩，加快查询速度
ads是text，gzip格式

问题总结
1、flink入hive数据库怎么验证当前小时数据已经入完。
2、通过flinksql进行数据开发怎么监控每个节点的状态和参数。
flinksql监控
flink写入监控
3、我们的小时调度优化一下，需要你们帮忙优化一下

4、完成ARM主机上采集服务部署，待测试验证  完成了吗
5、网络带宽调整是否完成

插码侧实施进度方面（1）完成applicaiton集群17个程序的国产化与arm架构的适配测试工作。(2)完成pg库的国产化迁移与arm架构的适配测试工作。(3)完11个离线调度迁移，预计下线8个离线调度，还剩10离线调度正在进行中。(4)其余离线接口也在陆续迁移中。整体计划5月15日左右完成数据处理部分迁移。
 

#2024-04-24
本周进展：
1、flink消费kafka数据入hive，由hive组件方式转换成hivesql的形式，速度提升到5百万每分钟，月中数据稳定写入。
2、完成19个离线调度迁移，预计下线10个离线调度，进入数据核对阶段。
3、营服实时数据入库，flinksql程序优化。
    （1）json.fail-on-missing-field = 'true' -- 字段丢失任务不失败
    （2）json.ignore-parse-errors = 'false' -- 解析失败跳过
4、优化营服flink入hive数据库性能，入库速度由2百万每分钟提升到5百万每分钟。除分省调度外，其余18个离线调度代码已经全部完成开发。
5、营服flink消费IT加密数据，解密入营服kafka

在营服的接口机172.19.171.32通过lftp明天推送文件到网状网和磐道，推送速率只有1.6M/s,在IT云发送数据到网状网达到136M/s

营服数据入库问题梳理

1、营服flink消费

营服离线调度问题梳理


营服实时程序问题梳理


营服protobuf格式处理
1、解析为eventdto格式无法transform成evnetviweDto


 扩大带宽
 自动提交checkpoint
 调整max.poll.records
 减少tcp交互次数-增到分区数
 名称	              业务网IPV4	   承载网IP
cache-core-new-1	10.104.85.57	10.255.98.91
cache-core-new-2	10.104.85.38	10.255.98.66
cache-core-new-3	10.104.85.51	10.255.98.60
cache-core-new-4	10.104.85.60	10.255.98.59
cache-core-new-5	10.104.85.54	10.255.98.51
cache-core-new-6	10.104.85.41	10.255.98.54
cache-core-new-7	10.104.85.53	10.255.98.50
cache-core-new-8	10.104.85.55	10.255.98.47
cache-core-new-9	10.104.85.49	10.255.98.37
cache-core-new-10	10.104.85.59	10.255.98.35

名称	业务网IPV4	承载网IP
newkfk-6	10.104.24.244;	10.255.96.148;
newkfk-5	10.104.24.246;	10.255.96.154;
newkfk-4	10.104.81.175;	10.255.99.34;
newkfk-3	10.104.81.182;	10.255.99.35;
newkfk-2	10.104.81.176;	10.255.99.36;
newkfk-1	10.104.81.166;	10.255.99.60;

名称	业务网IPV4	承载网IP
application-6	10.104.83.139	10.255.103.33
application-5	10.104.83.135	10.255.103.18
application-4	10.104.83.132	10.255.103.17




淮安到网状网

@牛仔很忙的； 您好，这个插码的表最近数据量激增，目前数仓的空间已经预警了，接下来保留7天数据量的峰值大概是多少？数仓需不需要扩容？需要的话，扩多少？

1、你这个存储空间的变化应该是对应账期的数据量增加了，月初月末数据量增加属于正常业务现象，4月份和3月份的环比数据量差异不是很大。
2、这个数据量增长情况应该是插码数据的特征，符合业务的增长趋势，你们对数据仓库的存储规划需要你们自己来评估。


1、咱们现在开通的网络策略是boss，
磐道10.255.136.251
网状网10.255.95.34

已完成基于在线营服平台的分省系列、77011及智慧中台离线接口迁移。完成营服接口机推送磐道51系列大接口文件通过道苏州资源池主机进行数据转发，已经完成路由转发，预计5月21日进行51系列接口迁移。
计划5月15日正式上线，15号下线10台CH集群物理机和15台CDH机器。为保持数据传输切换稳定，计划6月初下线IT云资源池15台CDH机器。


经过测试，磐道苏州资源池主机：10.250.33.7/incoming/cmccsales_270cm已具备接收数据能力。并通过 20线程上传文件，最大网速可以达到400M/s

数据接口迁移方面：已完成基于在线营服平台的分省系列、77011及智慧中台离线接口迁移。已经完成51系列大接口文件通过营服接口机推送磐道苏州资源池主机的推送，预计5月21日进行51系列接口迁移。



【接口优化】77006曝光接口增加原生渠道数据
需求编号：202405214332